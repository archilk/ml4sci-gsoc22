{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kcQNYq6thIbP"
      },
      "outputs": [],
      "source": [
        "!tar zxvf './lens_data_alt.tgz' -C './data/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "R9ziD9a1hR75"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import layers, regularizers\n",
        "from keras.engine import data_adapter\n",
        "import matplotlib.pyplot as plot\n",
        "import csv\n",
        "import pandas as pd\n",
        "from astropy.io import fits\n",
        "from astropy.visualization import astropy_mpl_style\n",
        "import os\n",
        "import sys\n",
        "import random\n",
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "JYVilwxjhdOf"
      },
      "outputs": [],
      "source": [
        "SEED = 0\n",
        "keras.utils.set_random_seed(SEED)\n",
        "tf.config.experimental.enable_op_determinism()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "GJVaDCulhfVN"
      },
      "outputs": [],
      "source": [
        "BASEPATH = './data/lens_data' # Location of data\n",
        "MODELPATH = './weights' # Location of weights\n",
        "BATCH_SIZE = 128\n",
        "EPOCHS = 300\n",
        "LEARNING_RATE = 2e-5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "pWdkyMkRhhHk"
      },
      "outputs": [],
      "source": [
        "def load_train_data():\n",
        "  image_files = os.listdir(BASEPATH)\n",
        "\n",
        "  x, y = [], []\n",
        "  for filename in image_files:\n",
        "    temp = np.load(os.path.join(BASEPATH, filename), allow_pickle=True)\n",
        "    if len(temp) != 2:\n",
        "      continue\n",
        "    x_temp, y_temp = temp[0], temp[1]\n",
        "    x.append(x_temp)\n",
        "    y.append(y_temp)\n",
        "  \n",
        "  x = np.expand_dims(np.stack(x, axis=0), axis=-1) # Add channel axis\n",
        "  y = np.stack(y, axis=0)\n",
        "\n",
        "  np.save(os.path.join(BASEPATH, 'X.npy'), x)\n",
        "  np.save(os.path.join(BASEPATH, 'Y.npy'), y)\n",
        "\n",
        "  return x, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "SXlV87AahjBa"
      },
      "outputs": [],
      "source": [
        "# Load train data\n",
        "X_TRAIN, Y_TRAIN = load_train_data()\n",
        "\n",
        "# Standardize data\n",
        "X_TRAIN = ((X_TRAIN - np.mean(X_TRAIN, axis=(1, 2), keepdims=True))\n",
        "          / np.std(X_TRAIN, axis=(1, 2), keepdims=True))\n",
        "\n",
        "# Shuffle train data\n",
        "perm = np.random.permutation(len(X_TRAIN))\n",
        "X_TRAIN, Y_TRAIN = X_TRAIN[perm], Y_TRAIN[perm]\n",
        "\n",
        "# Train / Val split\n",
        "val_size = len(X_TRAIN) // 10\n",
        "X_VAL, Y_VAL = X_TRAIN[:val_size], Y_TRAIN[:val_size]\n",
        "X_TRAIN, Y_TRAIN = X_TRAIN[val_size:], Y_TRAIN[val_size:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "SU_bjUkNhoJz"
      },
      "outputs": [],
      "source": [
        "def make_model(image_shape):\n",
        "  image_inputs = keras.Input(shape=image_shape)\n",
        "  x = keras.Sequential([\n",
        "                        layers.RandomFlip(),\n",
        "                        layers.RandomRotation(0.5)\n",
        "                        ])(image_inputs)\n",
        "  \n",
        "  x = layers.Conv2D(16, 5)(x)\n",
        "  x = layers.BatchNormalization()(x)\n",
        "  x = layers.Activation('relu')(x)\n",
        "\n",
        "  for _ in range(3):\n",
        "    x = layers.Conv2D(32, 3)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "    x = layers.MaxPool2D()(x)\n",
        "  \n",
        "  for _ in range(2):\n",
        "    residual = layers.Conv2D(64, 1)(x)\n",
        "    x = layers.Conv2D(64, 3, padding='same')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "    x = layers.add([x, residual])\n",
        "\n",
        "  x = layers.Conv2D(128, 3)(x)\n",
        "  x = layers.BatchNormalization()(x)\n",
        "  x = layers.Activation('relu')(x)\n",
        "\n",
        "  x = layers.Flatten()(x)\n",
        "\n",
        "  x = layers.Dense(256, kernel_regularizer=regularizers.l2(1e-3))(x)\n",
        "  x = layers.LeakyReLU()(x)\n",
        "  x = layers.Dense(64, kernel_regularizer=regularizers.l2(1e-3))(x)\n",
        "  x = layers.LeakyReLU()(x)\n",
        "  x = layers.Dense(1)(x)\n",
        "  outputs = layers.LeakyReLU()(x)\n",
        "\n",
        "  return keras.Model(image_inputs, outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "-5klwWz0houB"
      },
      "outputs": [],
      "source": [
        "class TrackBestPerformance(keras.callbacks.Callback):\n",
        "  \"\"\"\n",
        "  Callback to keep track of model weights which give best val_auc\n",
        "  After training completes, the model is assigned with the best model weights\n",
        "  \"\"\"\n",
        "  def __init__(self, **kwargs):\n",
        "    super().__init__(**kwargs)\n",
        "    self.best_mse = 1\n",
        "    self.best_epoch = -1\n",
        "    self.best_weights = None\n",
        "  \n",
        "  def on_epoch_end(self, epoch, logs=None):\n",
        "    current_mse = logs['val_mse']\n",
        "    if current_mse <= self.best_mse:\n",
        "      self.best_mse = current_mse\n",
        "      self.best_epoch = epoch\n",
        "      self.best_weights = self.model.get_weights()\n",
        "  \n",
        "  def on_train_end(self, logs=None):\n",
        "    self.model.set_weights(self.best_weights)\n",
        "    print(f'Best validation MSE is {self.best_mse} on epoch #{self.best_epoch + 1}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B0ae_IyLhskp",
        "outputId": "4cace515-bf13-46fa-d70c-b091991242a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/300\n",
            "  6/563 [..............................] - ETA: 25s - loss: 12.6226 - mse: 0.3754 - rmse: 0.6127WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0150s vs `on_train_batch_end` time: 0.0268s). Check your callbacks.\n",
            "563/563 [==============================] - 36s 45ms/step - loss: 1.1763 - mse: 0.0178 - rmse: 0.1334 - val_loss: 0.7967 - val_mse: 0.0060 - val_rmse: 0.0776\n",
            "Epoch 2/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.7325 - mse: 0.0041 - rmse: 0.0637 - val_loss: 0.7266 - val_mse: 0.0040 - val_rmse: 0.0630\n",
            "Epoch 3/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.6861 - mse: 0.0028 - rmse: 0.0527 - val_loss: 0.6945 - val_mse: 0.0031 - val_rmse: 0.0560\n",
            "Epoch 4/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.6643 - mse: 0.0023 - rmse: 0.0479 - val_loss: 0.6598 - val_mse: 0.0023 - val_rmse: 0.0477\n",
            "Epoch 5/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.6451 - mse: 0.0019 - rmse: 0.0439 - val_loss: 0.6576 - val_mse: 0.0025 - val_rmse: 0.0496\n",
            "Epoch 6/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.6347 - mse: 0.0019 - rmse: 0.0433 - val_loss: 0.6825 - val_mse: 0.0035 - val_rmse: 0.0594\n",
            "Epoch 7/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.6165 - mse: 0.0016 - rmse: 0.0399 - val_loss: 0.6282 - val_mse: 0.0021 - val_rmse: 0.0461\n",
            "Epoch 8/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.6067 - mse: 0.0016 - rmse: 0.0401 - val_loss: 0.6157 - val_mse: 0.0021 - val_rmse: 0.0455\n",
            "Epoch 9/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.6092 - mse: 0.0020 - rmse: 0.0451 - val_loss: 0.5922 - val_mse: 0.0017 - val_rmse: 0.0410\n",
            "Epoch 10/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.5726 - mse: 0.0013 - rmse: 0.0354 - val_loss: 0.5620 - val_mse: 0.0011 - val_rmse: 0.0333\n",
            "Epoch 11/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.5712 - mse: 0.0016 - rmse: 0.0399 - val_loss: 0.5781 - val_mse: 0.0020 - val_rmse: 0.0448\n",
            "Epoch 12/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.5489 - mse: 0.0013 - rmse: 0.0359 - val_loss: 0.5295 - val_mse: 8.8417e-04 - val_rmse: 0.0297\n",
            "Epoch 13/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.5393 - mse: 0.0014 - rmse: 0.0373 - val_loss: 0.5524 - val_mse: 0.0020 - val_rmse: 0.0449\n",
            "Epoch 14/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.5181 - mse: 0.0011 - rmse: 0.0339 - val_loss: 0.5048 - val_mse: 9.4408e-04 - val_rmse: 0.0307\n",
            "Epoch 15/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.5021 - mse: 0.0011 - rmse: 0.0327 - val_loss: 0.4905 - val_mse: 9.2692e-04 - val_rmse: 0.0304\n",
            "Epoch 16/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.4875 - mse: 0.0010 - rmse: 0.0323 - val_loss: 0.4698 - val_mse: 7.0945e-04 - val_rmse: 0.0266\n",
            "Epoch 17/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.4739 - mse: 0.0010 - rmse: 0.0323 - val_loss: 0.5128 - val_mse: 0.0025 - val_rmse: 0.0498\n",
            "Epoch 18/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.4575 - mse: 9.5185e-04 - rmse: 0.0309 - val_loss: 0.5075 - val_mse: 0.0027 - val_rmse: 0.0523\n",
            "Epoch 19/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.4397 - mse: 8.0553e-04 - rmse: 0.0284 - val_loss: 0.4332 - val_mse: 8.0823e-04 - val_rmse: 0.0284\n",
            "Epoch 20/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.4270 - mse: 8.0492e-04 - rmse: 0.0284 - val_loss: 0.4126 - val_mse: 5.4631e-04 - val_rmse: 0.0234\n",
            "Epoch 21/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.4149 - mse: 8.0180e-04 - rmse: 0.0283 - val_loss: 0.4722 - val_mse: 0.0028 - val_rmse: 0.0528\n",
            "Epoch 22/300\n",
            "563/563 [==============================] - 24s 44ms/step - loss: 0.4021 - mse: 7.6753e-04 - rmse: 0.0277 - val_loss: 0.3879 - val_mse: 5.0117e-04 - val_rmse: 0.0224\n",
            "Epoch 23/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.3915 - mse: 7.8268e-04 - rmse: 0.0280 - val_loss: 0.3825 - val_mse: 6.6986e-04 - val_rmse: 0.0259\n",
            "Epoch 24/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.3854 - mse: 9.0447e-04 - rmse: 0.0301 - val_loss: 0.3675 - val_mse: 4.9024e-04 - val_rmse: 0.0221\n",
            "Epoch 25/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.3640 - mse: 5.1798e-04 - rmse: 0.0228 - val_loss: 0.3804 - val_mse: 0.0012 - val_rmse: 0.0343\n",
            "Epoch 26/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.3595 - mse: 6.6096e-04 - rmse: 0.0257 - val_loss: 0.3633 - val_mse: 9.2768e-04 - val_rmse: 0.0305\n",
            "Epoch 27/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.3539 - mse: 7.6410e-04 - rmse: 0.0276 - val_loss: 0.3375 - val_mse: 3.8490e-04 - val_rmse: 0.0196\n",
            "Epoch 28/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.3366 - mse: 4.8336e-04 - rmse: 0.0220 - val_loss: 0.3298 - val_mse: 4.0195e-04 - val_rmse: 0.0200\n",
            "Epoch 29/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.3309 - mse: 5.6166e-04 - rmse: 0.0237 - val_loss: 0.3238 - val_mse: 4.6011e-04 - val_rmse: 0.0215\n",
            "Epoch 30/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.3232 - mse: 5.5788e-04 - rmse: 0.0236 - val_loss: 0.3958 - val_mse: 0.0030 - val_rmse: 0.0544\n",
            "Epoch 31/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.3166 - mse: 5.8500e-04 - rmse: 0.0242 - val_loss: 0.3068 - val_mse: 3.9289e-04 - val_rmse: 0.0198\n",
            "Epoch 32/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.3060 - mse: 4.8102e-04 - rmse: 0.0219 - val_loss: 0.3359 - val_mse: 0.0015 - val_rmse: 0.0392\n",
            "Epoch 33/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.2989 - mse: 4.8660e-04 - rmse: 0.0221 - val_loss: 0.2886 - val_mse: 2.8090e-04 - val_rmse: 0.0168\n",
            "Epoch 34/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.2897 - mse: 4.2435e-04 - rmse: 0.0206 - val_loss: 0.2833 - val_mse: 3.3872e-04 - val_rmse: 0.0184\n",
            "Epoch 35/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.2836 - mse: 4.4401e-04 - rmse: 0.0211 - val_loss: 0.2892 - val_mse: 7.2456e-04 - val_rmse: 0.0269\n",
            "Epoch 36/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.2780 - mse: 4.7583e-04 - rmse: 0.0218 - val_loss: 0.2703 - val_mse: 3.3921e-04 - val_rmse: 0.0184\n",
            "Epoch 37/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.2693 - mse: 4.0563e-04 - rmse: 0.0201 - val_loss: 0.2634 - val_mse: 3.2644e-04 - val_rmse: 0.0181\n",
            "Epoch 38/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.2613 - mse: 3.6133e-04 - rmse: 0.0190 - val_loss: 0.2632 - val_mse: 5.2579e-04 - val_rmse: 0.0229\n",
            "Epoch 39/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.2621 - mse: 5.8191e-04 - rmse: 0.0241 - val_loss: 0.2508 - val_mse: 3.0987e-04 - val_rmse: 0.0176\n",
            "Epoch 40/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.2504 - mse: 3.7931e-04 - rmse: 0.0195 - val_loss: 0.2486 - val_mse: 4.0869e-04 - val_rmse: 0.0202\n",
            "Epoch 41/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.2474 - mse: 4.5642e-04 - rmse: 0.0214 - val_loss: 0.2392 - val_mse: 2.8367e-04 - val_rmse: 0.0168\n",
            "Epoch 42/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.2396 - mse: 3.8222e-04 - rmse: 0.0196 - val_loss: 0.2385 - val_mse: 4.3516e-04 - val_rmse: 0.0209\n",
            "Epoch 43/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.2343 - mse: 3.9312e-04 - rmse: 0.0198 - val_loss: 0.2316 - val_mse: 3.9803e-04 - val_rmse: 0.0200\n",
            "Epoch 44/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.2289 - mse: 3.9924e-04 - rmse: 0.0200 - val_loss: 0.2210 - val_mse: 2.3997e-04 - val_rmse: 0.0155\n",
            "Epoch 45/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.2216 - mse: 3.4738e-04 - rmse: 0.0186 - val_loss: 0.2149 - val_mse: 2.2874e-04 - val_rmse: 0.0151\n",
            "Epoch 46/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.2163 - mse: 3.6210e-04 - rmse: 0.0190 - val_loss: 0.2097 - val_mse: 2.4439e-04 - val_rmse: 0.0156\n",
            "Epoch 47/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.2101 - mse: 3.4080e-04 - rmse: 0.0185 - val_loss: 0.2051 - val_mse: 2.7193e-04 - val_rmse: 0.0165\n",
            "Epoch 48/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.2031 - mse: 2.9566e-04 - rmse: 0.0172 - val_loss: 0.2052 - val_mse: 4.4925e-04 - val_rmse: 0.0212\n",
            "Epoch 49/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.1987 - mse: 3.2977e-04 - rmse: 0.0182 - val_loss: 0.1972 - val_mse: 3.6684e-04 - val_rmse: 0.0192\n",
            "Epoch 50/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.1946 - mse: 3.6022e-04 - rmse: 0.0190 - val_loss: 0.1917 - val_mse: 3.4911e-04 - val_rmse: 0.0187\n",
            "Epoch 51/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.1883 - mse: 3.1573e-04 - rmse: 0.0178 - val_loss: 0.1828 - val_mse: 2.2051e-04 - val_rmse: 0.0148\n",
            "Epoch 52/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.1851 - mse: 3.5416e-04 - rmse: 0.0188 - val_loss: 0.1811 - val_mse: 2.9325e-04 - val_rmse: 0.0171\n",
            "Epoch 53/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.1798 - mse: 3.1687e-04 - rmse: 0.0178 - val_loss: 0.1811 - val_mse: 4.2361e-04 - val_rmse: 0.0206\n",
            "Epoch 54/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.1745 - mse: 2.7941e-04 - rmse: 0.0167 - val_loss: 0.1724 - val_mse: 2.8319e-04 - val_rmse: 0.0168\n",
            "Epoch 55/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.1708 - mse: 2.9575e-04 - rmse: 0.0172 - val_loss: 0.1709 - val_mse: 3.6752e-04 - val_rmse: 0.0192\n",
            "Epoch 56/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.1668 - mse: 3.0148e-04 - rmse: 0.0174 - val_loss: 0.1621 - val_mse: 2.1648e-04 - val_rmse: 0.0147\n",
            "Epoch 57/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.1623 - mse: 2.8384e-04 - rmse: 0.0168 - val_loss: 0.1590 - val_mse: 2.4322e-04 - val_rmse: 0.0156\n",
            "Epoch 58/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.1577 - mse: 2.6206e-04 - rmse: 0.0162 - val_loss: 0.1576 - val_mse: 3.2454e-04 - val_rmse: 0.0180\n",
            "Epoch 59/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.1555 - mse: 3.0949e-04 - rmse: 0.0176 - val_loss: 0.1579 - val_mse: 4.3527e-04 - val_rmse: 0.0209\n",
            "Epoch 60/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.1517 - mse: 2.9543e-04 - rmse: 0.0172 - val_loss: 0.1500 - val_mse: 2.9853e-04 - val_rmse: 0.0173\n",
            "Epoch 61/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.1471 - mse: 2.5983e-04 - rmse: 0.0161 - val_loss: 0.1445 - val_mse: 2.3352e-04 - val_rmse: 0.0153\n",
            "Epoch 62/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.1441 - mse: 2.7347e-04 - rmse: 0.0165 - val_loss: 0.1402 - val_mse: 2.0466e-04 - val_rmse: 0.0143\n",
            "Epoch 63/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.1402 - mse: 2.5813e-04 - rmse: 0.0161 - val_loss: 0.1396 - val_mse: 2.9309e-04 - val_rmse: 0.0171\n",
            "Epoch 64/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.1363 - mse: 2.4142e-04 - rmse: 0.0155 - val_loss: 0.1357 - val_mse: 2.7723e-04 - val_rmse: 0.0167\n",
            "Epoch 65/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.1333 - mse: 2.5605e-04 - rmse: 0.0160 - val_loss: 0.1298 - val_mse: 1.9901e-04 - val_rmse: 0.0141\n",
            "Epoch 66/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.1295 - mse: 2.4022e-04 - rmse: 0.0155 - val_loss: 0.1266 - val_mse: 2.0397e-04 - val_rmse: 0.0143\n",
            "Epoch 67/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.1260 - mse: 2.3164e-04 - rmse: 0.0152 - val_loss: 0.1233 - val_mse: 1.9727e-04 - val_rmse: 0.0140\n",
            "Epoch 68/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.1235 - mse: 2.5297e-04 - rmse: 0.0159 - val_loss: 0.1276 - val_mse: 4.3055e-04 - val_rmse: 0.0207\n",
            "Epoch 69/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.1201 - mse: 2.3578e-04 - rmse: 0.0154 - val_loss: 0.1213 - val_mse: 3.1809e-04 - val_rmse: 0.0178\n",
            "Epoch 70/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.1169 - mse: 2.2526e-04 - rmse: 0.0150 - val_loss: 0.1141 - val_mse: 1.8342e-04 - val_rmse: 0.0135\n",
            "Epoch 71/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.1139 - mse: 2.1836e-04 - rmse: 0.0148 - val_loss: 0.1139 - val_mse: 2.6282e-04 - val_rmse: 0.0162\n",
            "Epoch 72/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.1120 - mse: 2.3146e-04 - rmse: 0.0152 - val_loss: 0.1196 - val_mse: 5.1507e-04 - val_rmse: 0.0227\n",
            "Epoch 73/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.1084 - mse: 2.0354e-04 - rmse: 0.0143 - val_loss: 0.1072 - val_mse: 2.0983e-04 - val_rmse: 0.0145\n",
            "Epoch 74/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.1058 - mse: 2.0840e-04 - rmse: 0.0144 - val_loss: 0.1082 - val_mse: 3.2447e-04 - val_rmse: 0.0180\n",
            "Epoch 75/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.1035 - mse: 2.1112e-04 - rmse: 0.0145 - val_loss: 0.1013 - val_mse: 1.8229e-04 - val_rmse: 0.0135\n",
            "Epoch 76/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.1011 - mse: 2.1054e-04 - rmse: 0.0145 - val_loss: 0.0999 - val_mse: 2.0239e-04 - val_rmse: 0.0142\n",
            "Epoch 77/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0992 - mse: 2.2109e-04 - rmse: 0.0149 - val_loss: 0.1061 - val_mse: 4.7503e-04 - val_rmse: 0.0218\n",
            "Epoch 78/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0986 - mse: 2.5090e-04 - rmse: 0.0158 - val_loss: 0.0967 - val_mse: 2.0948e-04 - val_rmse: 0.0145\n",
            "Epoch 79/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0955 - mse: 2.0670e-04 - rmse: 0.0144 - val_loss: 0.0972 - val_mse: 2.9389e-04 - val_rmse: 0.0171\n",
            "Epoch 80/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0928 - mse: 1.8404e-04 - rmse: 0.0136 - val_loss: 0.0921 - val_mse: 1.9602e-04 - val_rmse: 0.0140\n",
            "Epoch 81/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0912 - mse: 1.9802e-04 - rmse: 0.0141 - val_loss: 0.0894 - val_mse: 1.7211e-04 - val_rmse: 0.0131\n",
            "Epoch 82/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0890 - mse: 1.8700e-04 - rmse: 0.0137 - val_loss: 0.0879 - val_mse: 1.8395e-04 - val_rmse: 0.0136\n",
            "Epoch 83/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0878 - mse: 2.0060e-04 - rmse: 0.0142 - val_loss: 0.0866 - val_mse: 1.8850e-04 - val_rmse: 0.0137\n",
            "Epoch 84/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0853 - mse: 1.7713e-04 - rmse: 0.0133 - val_loss: 0.0880 - val_mse: 2.9378e-04 - val_rmse: 0.0171\n",
            "Epoch 85/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0835 - mse: 1.7702e-04 - rmse: 0.0133 - val_loss: 0.0822 - val_mse: 1.6486e-04 - val_rmse: 0.0128\n",
            "Epoch 86/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0818 - mse: 1.7958e-04 - rmse: 0.0134 - val_loss: 0.0812 - val_mse: 1.9125e-04 - val_rmse: 0.0138\n",
            "Epoch 87/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0802 - mse: 1.8409e-04 - rmse: 0.0136 - val_loss: 0.0795 - val_mse: 1.7007e-04 - val_rmse: 0.0130\n",
            "Epoch 88/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0785 - mse: 1.7425e-04 - rmse: 0.0132 - val_loss: 0.0810 - val_mse: 2.7702e-04 - val_rmse: 0.0166\n",
            "Epoch 89/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0766 - mse: 1.6717e-04 - rmse: 0.0129 - val_loss: 0.0758 - val_mse: 1.6956e-04 - val_rmse: 0.0130\n",
            "Epoch 90/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0753 - mse: 1.7614e-04 - rmse: 0.0133 - val_loss: 0.0745 - val_mse: 1.7551e-04 - val_rmse: 0.0132\n",
            "Epoch 91/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0740 - mse: 1.7173e-04 - rmse: 0.0131 - val_loss: 0.0743 - val_mse: 2.0152e-04 - val_rmse: 0.0142\n",
            "Epoch 92/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0725 - mse: 1.7048e-04 - rmse: 0.0131 - val_loss: 0.0719 - val_mse: 1.7600e-04 - val_rmse: 0.0133\n",
            "Epoch 93/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0708 - mse: 1.6430e-04 - rmse: 0.0128 - val_loss: 0.0755 - val_mse: 3.3592e-04 - val_rmse: 0.0183\n",
            "Epoch 94/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0707 - mse: 1.8164e-04 - rmse: 0.0135 - val_loss: 0.0715 - val_mse: 2.2928e-04 - val_rmse: 0.0151\n",
            "Epoch 95/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0686 - mse: 1.6061e-04 - rmse: 0.0127 - val_loss: 0.0680 - val_mse: 1.6182e-04 - val_rmse: 0.0127\n",
            "Epoch 96/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0673 - mse: 1.6056e-04 - rmse: 0.0127 - val_loss: 0.0697 - val_mse: 2.5528e-04 - val_rmse: 0.0160\n",
            "Epoch 97/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0661 - mse: 1.5455e-04 - rmse: 0.0124 - val_loss: 0.0658 - val_mse: 1.6559e-04 - val_rmse: 0.0129\n",
            "Epoch 98/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0648 - mse: 1.5317e-04 - rmse: 0.0124 - val_loss: 0.0668 - val_mse: 2.3771e-04 - val_rmse: 0.0154\n",
            "Epoch 99/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0639 - mse: 1.6293e-04 - rmse: 0.0128 - val_loss: 0.0632 - val_mse: 1.5832e-04 - val_rmse: 0.0126\n",
            "Epoch 100/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0623 - mse: 1.4892e-04 - rmse: 0.0122 - val_loss: 0.0620 - val_mse: 1.6161e-04 - val_rmse: 0.0127\n",
            "Epoch 101/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0616 - mse: 1.5793e-04 - rmse: 0.0126 - val_loss: 0.0611 - val_mse: 1.5561e-04 - val_rmse: 0.0125\n",
            "Epoch 102/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0600 - mse: 1.4333e-04 - rmse: 0.0120 - val_loss: 0.0616 - val_mse: 2.1317e-04 - val_rmse: 0.0146\n",
            "Epoch 103/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0594 - mse: 1.5373e-04 - rmse: 0.0124 - val_loss: 0.0594 - val_mse: 1.7120e-04 - val_rmse: 0.0131\n",
            "Epoch 104/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0580 - mse: 1.4608e-04 - rmse: 0.0121 - val_loss: 0.0575 - val_mse: 1.5046e-04 - val_rmse: 0.0123\n",
            "Epoch 105/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0587 - mse: 1.8282e-04 - rmse: 0.0135 - val_loss: 0.0614 - val_mse: 2.7090e-04 - val_rmse: 0.0165\n",
            "Epoch 106/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0570 - mse: 1.5109e-04 - rmse: 0.0123 - val_loss: 0.0566 - val_mse: 1.5439e-04 - val_rmse: 0.0124\n",
            "Epoch 107/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0560 - mse: 1.4997e-04 - rmse: 0.0122 - val_loss: 0.0554 - val_mse: 1.4634e-04 - val_rmse: 0.0121\n",
            "Epoch 108/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0548 - mse: 1.3822e-04 - rmse: 0.0118 - val_loss: 0.0549 - val_mse: 1.5705e-04 - val_rmse: 0.0125\n",
            "Epoch 109/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0539 - mse: 1.3874e-04 - rmse: 0.0118 - val_loss: 0.0543 - val_mse: 1.6682e-04 - val_rmse: 0.0129\n",
            "Epoch 110/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0530 - mse: 1.3962e-04 - rmse: 0.0118 - val_loss: 0.0543 - val_mse: 1.9645e-04 - val_rmse: 0.0140\n",
            "Epoch 111/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0524 - mse: 1.4687e-04 - rmse: 0.0121 - val_loss: 0.0520 - val_mse: 1.4235e-04 - val_rmse: 0.0119\n",
            "Epoch 112/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0512 - mse: 1.3654e-04 - rmse: 0.0117 - val_loss: 0.0522 - val_mse: 1.8369e-04 - val_rmse: 0.0136\n",
            "Epoch 113/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0503 - mse: 1.3616e-04 - rmse: 0.0117 - val_loss: 0.0508 - val_mse: 1.6766e-04 - val_rmse: 0.0129\n",
            "Epoch 114/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0495 - mse: 1.3816e-04 - rmse: 0.0118 - val_loss: 0.0492 - val_mse: 1.3998e-04 - val_rmse: 0.0118\n",
            "Epoch 115/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0484 - mse: 1.3099e-04 - rmse: 0.0114 - val_loss: 0.0480 - val_mse: 1.3421e-04 - val_rmse: 0.0116\n",
            "Epoch 116/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0487 - mse: 1.5532e-04 - rmse: 0.0125 - val_loss: 0.0489 - val_mse: 1.5996e-04 - val_rmse: 0.0126\n",
            "Epoch 117/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0476 - mse: 1.4037e-04 - rmse: 0.0118 - val_loss: 0.0489 - val_mse: 1.9406e-04 - val_rmse: 0.0139\n",
            "Epoch 118/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0464 - mse: 1.2920e-04 - rmse: 0.0114 - val_loss: 0.0467 - val_mse: 1.5195e-04 - val_rmse: 0.0123\n",
            "Epoch 119/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0457 - mse: 1.2975e-04 - rmse: 0.0114 - val_loss: 0.0457 - val_mse: 1.4311e-04 - val_rmse: 0.0120\n",
            "Epoch 120/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0448 - mse: 1.2780e-04 - rmse: 0.0113 - val_loss: 0.0446 - val_mse: 1.3470e-04 - val_rmse: 0.0116\n",
            "Epoch 121/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0445 - mse: 1.3639e-04 - rmse: 0.0117 - val_loss: 0.0461 - val_mse: 1.8291e-04 - val_rmse: 0.0135\n",
            "Epoch 122/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0438 - mse: 1.3110e-04 - rmse: 0.0115 - val_loss: 0.0448 - val_mse: 1.7759e-04 - val_rmse: 0.0133\n",
            "Epoch 123/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0429 - mse: 1.2775e-04 - rmse: 0.0113 - val_loss: 0.0433 - val_mse: 1.5391e-04 - val_rmse: 0.0124\n",
            "Epoch 124/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0422 - mse: 1.2711e-04 - rmse: 0.0113 - val_loss: 0.0424 - val_mse: 1.4724e-04 - val_rmse: 0.0121\n",
            "Epoch 125/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0413 - mse: 1.2285e-04 - rmse: 0.0111 - val_loss: 0.0422 - val_mse: 1.6516e-04 - val_rmse: 0.0129\n",
            "Epoch 126/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0418 - mse: 1.4541e-04 - rmse: 0.0121 - val_loss: 0.0417 - val_mse: 1.4834e-04 - val_rmse: 0.0122\n",
            "Epoch 127/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0408 - mse: 1.3382e-04 - rmse: 0.0116 - val_loss: 0.0408 - val_mse: 1.4643e-04 - val_rmse: 0.0121\n",
            "Epoch 128/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0397 - mse: 1.2331e-04 - rmse: 0.0111 - val_loss: 0.0397 - val_mse: 1.3205e-04 - val_rmse: 0.0115\n",
            "Epoch 129/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0390 - mse: 1.2029e-04 - rmse: 0.0110 - val_loss: 0.0430 - val_mse: 2.5514e-04 - val_rmse: 0.0160\n",
            "Epoch 130/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0388 - mse: 1.2685e-04 - rmse: 0.0113 - val_loss: 0.0393 - val_mse: 1.5510e-04 - val_rmse: 0.0125\n",
            "Epoch 131/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0378 - mse: 1.1859e-04 - rmse: 0.0109 - val_loss: 0.0378 - val_mse: 1.2858e-04 - val_rmse: 0.0113\n",
            "Epoch 132/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0372 - mse: 1.1868e-04 - rmse: 0.0109 - val_loss: 0.0372 - val_mse: 1.2620e-04 - val_rmse: 0.0112\n",
            "Epoch 133/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0366 - mse: 1.1846e-04 - rmse: 0.0109 - val_loss: 0.0385 - val_mse: 1.9143e-04 - val_rmse: 0.0138\n",
            "Epoch 134/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0357 - mse: 1.1615e-04 - rmse: 0.0108 - val_loss: 0.0416 - val_mse: 3.0882e-04 - val_rmse: 0.0176\n",
            "Epoch 135/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0355 - mse: 1.2562e-04 - rmse: 0.0112 - val_loss: 0.0354 - val_mse: 1.2631e-04 - val_rmse: 0.0112\n",
            "Epoch 136/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0347 - mse: 1.1826e-04 - rmse: 0.0109 - val_loss: 0.0346 - val_mse: 1.2962e-04 - val_rmse: 0.0114\n",
            "Epoch 137/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0339 - mse: 1.1648e-04 - rmse: 0.0108 - val_loss: 0.0341 - val_mse: 1.2818e-04 - val_rmse: 0.0113\n",
            "Epoch 138/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0336 - mse: 1.2338e-04 - rmse: 0.0111 - val_loss: 0.0346 - val_mse: 1.3693e-04 - val_rmse: 0.0117\n",
            "Epoch 139/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0333 - mse: 1.2157e-04 - rmse: 0.0110 - val_loss: 0.0342 - val_mse: 1.6368e-04 - val_rmse: 0.0128\n",
            "Epoch 140/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0323 - mse: 1.1354e-04 - rmse: 0.0107 - val_loss: 0.0351 - val_mse: 2.1168e-04 - val_rmse: 0.0145\n",
            "Epoch 141/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0317 - mse: 1.1339e-04 - rmse: 0.0106 - val_loss: 0.0335 - val_mse: 1.7958e-04 - val_rmse: 0.0134\n",
            "Epoch 142/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0313 - mse: 1.1581e-04 - rmse: 0.0108 - val_loss: 0.0311 - val_mse: 1.1740e-04 - val_rmse: 0.0108\n",
            "Epoch 143/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0306 - mse: 1.1173e-04 - rmse: 0.0106 - val_loss: 0.0307 - val_mse: 1.2733e-04 - val_rmse: 0.0113\n",
            "Epoch 144/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0317 - mse: 1.3826e-04 - rmse: 0.0118 - val_loss: 0.0316 - val_mse: 1.4578e-04 - val_rmse: 0.0121\n",
            "Epoch 145/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0302 - mse: 1.1343e-04 - rmse: 0.0107 - val_loss: 0.0299 - val_mse: 1.1558e-04 - val_rmse: 0.0108\n",
            "Epoch 146/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0296 - mse: 1.1230e-04 - rmse: 0.0106 - val_loss: 0.0301 - val_mse: 1.3514e-04 - val_rmse: 0.0116\n",
            "Epoch 147/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0290 - mse: 1.0908e-04 - rmse: 0.0104 - val_loss: 0.0304 - val_mse: 1.6223e-04 - val_rmse: 0.0127\n",
            "Epoch 148/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0285 - mse: 1.1029e-04 - rmse: 0.0105 - val_loss: 0.0285 - val_mse: 1.1899e-04 - val_rmse: 0.0109\n",
            "Epoch 149/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0285 - mse: 1.1463e-04 - rmse: 0.0107 - val_loss: 0.0283 - val_mse: 1.2038e-04 - val_rmse: 0.0110\n",
            "Epoch 150/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0276 - mse: 1.0690e-04 - rmse: 0.0103 - val_loss: 0.0275 - val_mse: 1.1392e-04 - val_rmse: 0.0107\n",
            "Epoch 151/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0271 - mse: 1.0824e-04 - rmse: 0.0104 - val_loss: 0.0269 - val_mse: 1.1264e-04 - val_rmse: 0.0106\n",
            "Epoch 152/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0267 - mse: 1.0981e-04 - rmse: 0.0105 - val_loss: 0.0265 - val_mse: 1.1614e-04 - val_rmse: 0.0108\n",
            "Epoch 153/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0262 - mse: 1.0863e-04 - rmse: 0.0104 - val_loss: 0.0266 - val_mse: 1.3096e-04 - val_rmse: 0.0114\n",
            "Epoch 154/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0260 - mse: 1.1186e-04 - rmse: 0.0106 - val_loss: 0.0276 - val_mse: 1.6263e-04 - val_rmse: 0.0128\n",
            "Epoch 155/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0255 - mse: 1.0835e-04 - rmse: 0.0104 - val_loss: 0.0262 - val_mse: 1.4057e-04 - val_rmse: 0.0119\n",
            "Epoch 156/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0249 - mse: 1.0672e-04 - rmse: 0.0103 - val_loss: 0.0249 - val_mse: 1.1094e-04 - val_rmse: 0.0105\n",
            "Epoch 157/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0245 - mse: 1.0470e-04 - rmse: 0.0102 - val_loss: 0.0254 - val_mse: 1.4341e-04 - val_rmse: 0.0120\n",
            "Epoch 158/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0248 - mse: 1.1843e-04 - rmse: 0.0109 - val_loss: 0.0256 - val_mse: 1.4921e-04 - val_rmse: 0.0122\n",
            "Epoch 159/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0240 - mse: 1.0726e-04 - rmse: 0.0104 - val_loss: 0.0240 - val_mse: 1.1585e-04 - val_rmse: 0.0108\n",
            "Epoch 160/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0235 - mse: 1.0456e-04 - rmse: 0.0102 - val_loss: 0.0234 - val_mse: 1.0810e-04 - val_rmse: 0.0104\n",
            "Epoch 161/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0231 - mse: 1.0388e-04 - rmse: 0.0102 - val_loss: 0.0243 - val_mse: 1.4841e-04 - val_rmse: 0.0122\n",
            "Epoch 162/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0226 - mse: 1.0419e-04 - rmse: 0.0102 - val_loss: 0.0225 - val_mse: 1.0949e-04 - val_rmse: 0.0105\n",
            "Epoch 163/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0221 - mse: 1.0401e-04 - rmse: 0.0102 - val_loss: 0.0226 - val_mse: 1.2962e-04 - val_rmse: 0.0114\n",
            "Epoch 164/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0222 - mse: 1.1256e-04 - rmse: 0.0106 - val_loss: 0.0225 - val_mse: 1.3384e-04 - val_rmse: 0.0116\n",
            "Epoch 165/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0214 - mse: 1.0451e-04 - rmse: 0.0102 - val_loss: 0.0231 - val_mse: 1.6847e-04 - val_rmse: 0.0130\n",
            "Epoch 166/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0208 - mse: 1.0161e-04 - rmse: 0.0101 - val_loss: 0.0208 - val_mse: 1.0758e-04 - val_rmse: 0.0104\n",
            "Epoch 167/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0203 - mse: 1.0032e-04 - rmse: 0.0100 - val_loss: 0.0210 - val_mse: 1.2881e-04 - val_rmse: 0.0113\n",
            "Epoch 168/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0206 - mse: 1.1680e-04 - rmse: 0.0108 - val_loss: 0.0202 - val_mse: 1.1273e-04 - val_rmse: 0.0106\n",
            "Epoch 169/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0199 - mse: 1.1051e-04 - rmse: 0.0105 - val_loss: 0.0197 - val_mse: 1.1014e-04 - val_rmse: 0.0105\n",
            "Epoch 170/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0193 - mse: 1.0340e-04 - rmse: 0.0102 - val_loss: 0.0192 - val_mse: 1.0902e-04 - val_rmse: 0.0104\n",
            "Epoch 171/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0192 - mse: 1.0920e-04 - rmse: 0.0104 - val_loss: 0.0190 - val_mse: 1.1252e-04 - val_rmse: 0.0106\n",
            "Epoch 172/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0185 - mse: 1.0195e-04 - rmse: 0.0101 - val_loss: 0.0190 - val_mse: 1.2460e-04 - val_rmse: 0.0112\n",
            "Epoch 173/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0183 - mse: 1.0580e-04 - rmse: 0.0103 - val_loss: 0.0183 - val_mse: 1.0989e-04 - val_rmse: 0.0105\n",
            "Epoch 174/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0178 - mse: 1.0224e-04 - rmse: 0.0101 - val_loss: 0.0179 - val_mse: 1.1148e-04 - val_rmse: 0.0106\n",
            "Epoch 175/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0174 - mse: 1.0165e-04 - rmse: 0.0101 - val_loss: 0.0185 - val_mse: 1.1870e-04 - val_rmse: 0.0109\n",
            "Epoch 176/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0173 - mse: 1.0207e-04 - rmse: 0.0101 - val_loss: 0.0170 - val_mse: 1.0583e-04 - val_rmse: 0.0103\n",
            "Epoch 177/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0167 - mse: 9.9523e-05 - rmse: 0.0100 - val_loss: 0.0167 - val_mse: 1.0497e-04 - val_rmse: 0.0102\n",
            "Epoch 178/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0165 - mse: 1.0337e-04 - rmse: 0.0102 - val_loss: 0.0177 - val_mse: 1.4306e-04 - val_rmse: 0.0120\n",
            "Epoch 179/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0161 - mse: 1.0004e-04 - rmse: 0.0100 - val_loss: 0.0160 - val_mse: 1.0480e-04 - val_rmse: 0.0102\n",
            "Epoch 180/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0161 - mse: 1.0763e-04 - rmse: 0.0104 - val_loss: 0.0160 - val_mse: 1.0951e-04 - val_rmse: 0.0105\n",
            "Epoch 181/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0155 - mse: 9.7454e-05 - rmse: 0.0099 - val_loss: 0.0160 - val_mse: 1.2104e-04 - val_rmse: 0.0110\n",
            "Epoch 182/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0151 - mse: 9.5856e-05 - rmse: 0.0098 - val_loss: 0.0162 - val_mse: 1.3613e-04 - val_rmse: 0.0117\n",
            "Epoch 183/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0149 - mse: 9.9232e-05 - rmse: 0.0100 - val_loss: 0.0148 - val_mse: 1.0496e-04 - val_rmse: 0.0102\n",
            "Epoch 184/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0145 - mse: 9.8602e-05 - rmse: 0.0099 - val_loss: 0.0145 - val_mse: 1.0304e-04 - val_rmse: 0.0102\n",
            "Epoch 185/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0144 - mse: 1.0214e-04 - rmse: 0.0101 - val_loss: 0.0144 - val_mse: 1.0813e-04 - val_rmse: 0.0104\n",
            "Epoch 186/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0139 - mse: 9.7577e-05 - rmse: 0.0099 - val_loss: 0.0156 - val_mse: 1.5332e-04 - val_rmse: 0.0124\n",
            "Epoch 187/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0135 - mse: 9.4264e-05 - rmse: 0.0097 - val_loss: 0.0138 - val_mse: 1.0927e-04 - val_rmse: 0.0105\n",
            "Epoch 188/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0134 - mse: 9.7733e-05 - rmse: 0.0099 - val_loss: 0.0135 - val_mse: 1.0669e-04 - val_rmse: 0.0103\n",
            "Epoch 189/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0130 - mse: 9.5077e-05 - rmse: 0.0098 - val_loss: 0.0149 - val_mse: 1.5429e-04 - val_rmse: 0.0124\n",
            "Epoch 190/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0127 - mse: 9.5387e-05 - rmse: 0.0098 - val_loss: 0.0140 - val_mse: 1.3850e-04 - val_rmse: 0.0118\n",
            "Epoch 191/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0124 - mse: 9.4444e-05 - rmse: 0.0097 - val_loss: 0.0139 - val_mse: 1.4173e-04 - val_rmse: 0.0119\n",
            "Epoch 192/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0122 - mse: 9.6060e-05 - rmse: 0.0098 - val_loss: 0.0124 - val_mse: 1.0672e-04 - val_rmse: 0.0103\n",
            "Epoch 193/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0118 - mse: 9.4014e-05 - rmse: 0.0097 - val_loss: 0.0121 - val_mse: 1.0078e-04 - val_rmse: 0.0100\n",
            "Epoch 194/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0115 - mse: 9.3464e-05 - rmse: 0.0097 - val_loss: 0.0120 - val_mse: 1.1422e-04 - val_rmse: 0.0107\n",
            "Epoch 195/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0117 - mse: 1.0065e-04 - rmse: 0.0100 - val_loss: 0.0131 - val_mse: 1.5278e-04 - val_rmse: 0.0124\n",
            "Epoch 196/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0111 - mse: 9.2903e-05 - rmse: 0.0096 - val_loss: 0.0120 - val_mse: 1.2276e-04 - val_rmse: 0.0111\n",
            "Epoch 197/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0110 - mse: 9.4658e-05 - rmse: 0.0097 - val_loss: 0.0112 - val_mse: 1.0551e-04 - val_rmse: 0.0103\n",
            "Epoch 198/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0108 - mse: 9.4808e-05 - rmse: 0.0097 - val_loss: 0.0109 - val_mse: 1.0342e-04 - val_rmse: 0.0102\n",
            "Epoch 199/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0105 - mse: 9.2375e-05 - rmse: 0.0096 - val_loss: 0.0106 - val_mse: 9.7768e-05 - val_rmse: 0.0099\n",
            "Epoch 200/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0104 - mse: 9.3387e-05 - rmse: 0.0097 - val_loss: 0.0203 - val_mse: 4.0402e-04 - val_rmse: 0.0201\n",
            "Epoch 201/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0104 - mse: 9.5443e-05 - rmse: 0.0098 - val_loss: 0.0125 - val_mse: 1.7006e-04 - val_rmse: 0.0130\n",
            "Epoch 202/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0099 - mse: 9.0539e-05 - rmse: 0.0095 - val_loss: 0.0100 - val_mse: 9.6224e-05 - val_rmse: 0.0098\n",
            "Epoch 203/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0099 - mse: 9.3344e-05 - rmse: 0.0097 - val_loss: 0.0101 - val_mse: 1.0396e-04 - val_rmse: 0.0102\n",
            "Epoch 204/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0096 - mse: 9.0238e-05 - rmse: 0.0095 - val_loss: 0.0097 - val_mse: 9.7057e-05 - val_rmse: 0.0099\n",
            "Epoch 205/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0095 - mse: 9.3739e-05 - rmse: 0.0097 - val_loss: 0.0112 - val_mse: 1.4156e-04 - val_rmse: 0.0119\n",
            "Epoch 206/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0097 - mse: 1.0199e-04 - rmse: 0.0101 - val_loss: 0.0095 - val_mse: 1.0130e-04 - val_rmse: 0.0101\n",
            "Epoch 207/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0092 - mse: 9.3955e-05 - rmse: 0.0097 - val_loss: 0.0097 - val_mse: 1.1272e-04 - val_rmse: 0.0106\n",
            "Epoch 208/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0091 - mse: 9.3508e-05 - rmse: 0.0097 - val_loss: 0.0091 - val_mse: 9.7966e-05 - val_rmse: 0.0099\n",
            "Epoch 209/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0089 - mse: 9.3295e-05 - rmse: 0.0097 - val_loss: 0.0088 - val_mse: 9.5500e-05 - val_rmse: 0.0098\n",
            "Epoch 210/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0087 - mse: 9.2169e-05 - rmse: 0.0096 - val_loss: 0.0092 - val_mse: 1.1348e-04 - val_rmse: 0.0107\n",
            "Epoch 211/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0085 - mse: 9.1506e-05 - rmse: 0.0096 - val_loss: 0.0087 - val_mse: 1.0305e-04 - val_rmse: 0.0102\n",
            "Epoch 212/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0083 - mse: 9.1924e-05 - rmse: 0.0096 - val_loss: 0.0085 - val_mse: 1.0130e-04 - val_rmse: 0.0101\n",
            "Epoch 213/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0080 - mse: 8.9277e-05 - rmse: 0.0094 - val_loss: 0.0083 - val_mse: 1.0159e-04 - val_rmse: 0.0101\n",
            "Epoch 214/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0078 - mse: 8.9191e-05 - rmse: 0.0094 - val_loss: 0.0079 - val_mse: 9.4856e-05 - val_rmse: 0.0097\n",
            "Epoch 215/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0076 - mse: 8.9846e-05 - rmse: 0.0095 - val_loss: 0.0088 - val_mse: 1.3030e-04 - val_rmse: 0.0114\n",
            "Epoch 216/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0075 - mse: 9.0265e-05 - rmse: 0.0095 - val_loss: 0.0075 - val_mse: 9.4812e-05 - val_rmse: 0.0097\n",
            "Epoch 217/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0072 - mse: 8.9042e-05 - rmse: 0.0094 - val_loss: 0.0094 - val_mse: 1.5772e-04 - val_rmse: 0.0126\n",
            "Epoch 218/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0071 - mse: 8.9725e-05 - rmse: 0.0095 - val_loss: 0.0074 - val_mse: 9.7587e-05 - val_rmse: 0.0099\n",
            "Epoch 219/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0069 - mse: 8.9056e-05 - rmse: 0.0094 - val_loss: 0.0071 - val_mse: 9.7490e-05 - val_rmse: 0.0099\n",
            "Epoch 220/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0068 - mse: 8.8659e-05 - rmse: 0.0094 - val_loss: 0.0069 - val_mse: 9.4818e-05 - val_rmse: 0.0097\n",
            "Epoch 221/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0067 - mse: 8.9023e-05 - rmse: 0.0094 - val_loss: 0.0079 - val_mse: 1.3116e-04 - val_rmse: 0.0115\n",
            "Epoch 222/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0065 - mse: 8.7777e-05 - rmse: 0.0094 - val_loss: 0.0069 - val_mse: 1.0187e-04 - val_rmse: 0.0101\n",
            "Epoch 223/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0064 - mse: 8.8482e-05 - rmse: 0.0094 - val_loss: 0.0075 - val_mse: 1.2389e-04 - val_rmse: 0.0111\n",
            "Epoch 224/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0062 - mse: 8.7020e-05 - rmse: 0.0093 - val_loss: 0.0065 - val_mse: 9.6776e-05 - val_rmse: 0.0098\n",
            "Epoch 225/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0062 - mse: 8.7387e-05 - rmse: 0.0093 - val_loss: 0.0064 - val_mse: 9.7411e-05 - val_rmse: 0.0099\n",
            "Epoch 226/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0060 - mse: 8.6491e-05 - rmse: 0.0093 - val_loss: 0.0062 - val_mse: 9.4309e-05 - val_rmse: 0.0097\n",
            "Epoch 227/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0059 - mse: 8.6474e-05 - rmse: 0.0093 - val_loss: 0.0062 - val_mse: 9.5045e-05 - val_rmse: 0.0097\n",
            "Epoch 228/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0059 - mse: 8.7015e-05 - rmse: 0.0093 - val_loss: 0.0060 - val_mse: 9.5071e-05 - val_rmse: 0.0098\n",
            "Epoch 229/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0057 - mse: 8.5862e-05 - rmse: 0.0093 - val_loss: 0.0065 - val_mse: 1.0550e-04 - val_rmse: 0.0103\n",
            "Epoch 230/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0058 - mse: 8.9773e-05 - rmse: 0.0095 - val_loss: 0.0059 - val_mse: 9.5107e-05 - val_rmse: 0.0098\n",
            "Epoch 231/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0056 - mse: 8.7461e-05 - rmse: 0.0094 - val_loss: 0.0056 - val_mse: 8.9079e-05 - val_rmse: 0.0094\n",
            "Epoch 232/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0055 - mse: 8.6388e-05 - rmse: 0.0093 - val_loss: 0.0065 - val_mse: 1.1635e-04 - val_rmse: 0.0108\n",
            "Epoch 233/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0054 - mse: 8.5794e-05 - rmse: 0.0093 - val_loss: 0.0062 - val_mse: 1.1153e-04 - val_rmse: 0.0106\n",
            "Epoch 234/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0053 - mse: 8.4679e-05 - rmse: 0.0092 - val_loss: 0.0058 - val_mse: 1.0055e-04 - val_rmse: 0.0100\n",
            "Epoch 235/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0053 - mse: 8.5154e-05 - rmse: 0.0092 - val_loss: 0.0057 - val_mse: 9.9788e-05 - val_rmse: 0.0100\n",
            "Epoch 236/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0052 - mse: 8.5044e-05 - rmse: 0.0092 - val_loss: 0.0055 - val_mse: 9.3388e-05 - val_rmse: 0.0097\n",
            "Epoch 237/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0051 - mse: 8.5099e-05 - rmse: 0.0092 - val_loss: 0.0057 - val_mse: 1.0574e-04 - val_rmse: 0.0103\n",
            "Epoch 238/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0051 - mse: 8.5512e-05 - rmse: 0.0092 - val_loss: 0.0054 - val_mse: 9.6909e-05 - val_rmse: 0.0098\n",
            "Epoch 239/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0049 - mse: 8.3697e-05 - rmse: 0.0091 - val_loss: 0.0050 - val_mse: 8.7311e-05 - val_rmse: 0.0093\n",
            "Epoch 240/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0049 - mse: 8.3795e-05 - rmse: 0.0092 - val_loss: 0.0050 - val_mse: 9.0014e-05 - val_rmse: 0.0095\n",
            "Epoch 241/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0048 - mse: 8.3379e-05 - rmse: 0.0091 - val_loss: 0.0051 - val_mse: 9.2928e-05 - val_rmse: 0.0096\n",
            "Epoch 242/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0048 - mse: 8.3649e-05 - rmse: 0.0091 - val_loss: 0.0051 - val_mse: 8.9426e-05 - val_rmse: 0.0095\n",
            "Epoch 243/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0048 - mse: 8.4879e-05 - rmse: 0.0092 - val_loss: 0.0050 - val_mse: 9.4268e-05 - val_rmse: 0.0097\n",
            "Epoch 244/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0047 - mse: 8.4391e-05 - rmse: 0.0092 - val_loss: 0.0058 - val_mse: 1.1984e-04 - val_rmse: 0.0109\n",
            "Epoch 245/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0046 - mse: 8.2769e-05 - rmse: 0.0091 - val_loss: 0.0047 - val_mse: 8.9297e-05 - val_rmse: 0.0094\n",
            "Epoch 246/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0046 - mse: 8.4859e-05 - rmse: 0.0092 - val_loss: 0.0049 - val_mse: 9.5696e-05 - val_rmse: 0.0098\n",
            "Epoch 247/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0044 - mse: 8.1773e-05 - rmse: 0.0090 - val_loss: 0.0050 - val_mse: 1.0176e-04 - val_rmse: 0.0101\n",
            "Epoch 248/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0044 - mse: 8.2993e-05 - rmse: 0.0091 - val_loss: 0.0047 - val_mse: 9.3009e-05 - val_rmse: 0.0096\n",
            "Epoch 249/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0044 - mse: 8.3560e-05 - rmse: 0.0091 - val_loss: 0.0046 - val_mse: 8.9080e-05 - val_rmse: 0.0094\n",
            "Epoch 250/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0043 - mse: 8.0576e-05 - rmse: 0.0090 - val_loss: 0.0044 - val_mse: 8.6807e-05 - val_rmse: 0.0093\n",
            "Epoch 251/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0043 - mse: 8.3094e-05 - rmse: 0.0091 - val_loss: 0.0049 - val_mse: 9.3187e-05 - val_rmse: 0.0097\n",
            "Epoch 252/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0043 - mse: 8.2016e-05 - rmse: 0.0091 - val_loss: 0.0047 - val_mse: 9.8964e-05 - val_rmse: 0.0099\n",
            "Epoch 253/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0041 - mse: 8.0647e-05 - rmse: 0.0090 - val_loss: 0.0044 - val_mse: 8.8808e-05 - val_rmse: 0.0094\n",
            "Epoch 254/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0041 - mse: 8.1431e-05 - rmse: 0.0090 - val_loss: 0.0044 - val_mse: 9.0497e-05 - val_rmse: 0.0095\n",
            "Epoch 255/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0041 - mse: 8.1167e-05 - rmse: 0.0090 - val_loss: 0.0047 - val_mse: 1.0042e-04 - val_rmse: 0.0100\n",
            "Epoch 256/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0041 - mse: 8.1224e-05 - rmse: 0.0090 - val_loss: 0.0042 - val_mse: 8.7652e-05 - val_rmse: 0.0094\n",
            "Epoch 257/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0041 - mse: 8.2524e-05 - rmse: 0.0091 - val_loss: 0.0049 - val_mse: 1.1031e-04 - val_rmse: 0.0105\n",
            "Epoch 258/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0040 - mse: 8.0620e-05 - rmse: 0.0090 - val_loss: 0.0042 - val_mse: 8.8840e-05 - val_rmse: 0.0094\n",
            "Epoch 259/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0040 - mse: 8.0801e-05 - rmse: 0.0090 - val_loss: 0.0044 - val_mse: 9.6867e-05 - val_rmse: 0.0098\n",
            "Epoch 260/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0040 - mse: 8.1677e-05 - rmse: 0.0090 - val_loss: 0.0048 - val_mse: 1.0825e-04 - val_rmse: 0.0104\n",
            "Epoch 261/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0039 - mse: 8.1542e-05 - rmse: 0.0090 - val_loss: 0.0064 - val_mse: 1.5828e-04 - val_rmse: 0.0126\n",
            "Epoch 262/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0038 - mse: 8.0234e-05 - rmse: 0.0090 - val_loss: 0.0048 - val_mse: 1.0988e-04 - val_rmse: 0.0105\n",
            "Epoch 263/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0039 - mse: 8.1131e-05 - rmse: 0.0090 - val_loss: 0.0040 - val_mse: 8.6293e-05 - val_rmse: 0.0093\n",
            "Epoch 264/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0038 - mse: 8.0506e-05 - rmse: 0.0090 - val_loss: 0.0043 - val_mse: 9.6930e-05 - val_rmse: 0.0098\n",
            "Epoch 265/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0038 - mse: 7.9456e-05 - rmse: 0.0089 - val_loss: 0.0040 - val_mse: 8.7719e-05 - val_rmse: 0.0094\n",
            "Epoch 266/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0038 - mse: 8.0941e-05 - rmse: 0.0090 - val_loss: 0.0040 - val_mse: 8.8509e-05 - val_rmse: 0.0094\n",
            "Epoch 267/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0037 - mse: 7.9409e-05 - rmse: 0.0089 - val_loss: 0.0038 - val_mse: 8.4575e-05 - val_rmse: 0.0092\n",
            "Epoch 268/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0038 - mse: 8.2046e-05 - rmse: 0.0091 - val_loss: 0.0046 - val_mse: 1.0785e-04 - val_rmse: 0.0104\n",
            "Epoch 269/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0037 - mse: 7.9015e-05 - rmse: 0.0089 - val_loss: 0.0043 - val_mse: 1.0141e-04 - val_rmse: 0.0101\n",
            "Epoch 270/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0036 - mse: 7.7867e-05 - rmse: 0.0088 - val_loss: 0.0038 - val_mse: 8.4720e-05 - val_rmse: 0.0092\n",
            "Epoch 271/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0037 - mse: 8.0071e-05 - rmse: 0.0089 - val_loss: 0.0038 - val_mse: 8.3289e-05 - val_rmse: 0.0091\n",
            "Epoch 272/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0036 - mse: 7.9536e-05 - rmse: 0.0089 - val_loss: 0.0039 - val_mse: 9.0149e-05 - val_rmse: 0.0095\n",
            "Epoch 273/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0036 - mse: 7.8667e-05 - rmse: 0.0089 - val_loss: 0.0054 - val_mse: 1.3582e-04 - val_rmse: 0.0117\n",
            "Epoch 274/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0036 - mse: 7.8749e-05 - rmse: 0.0089 - val_loss: 0.0052 - val_mse: 1.3019e-04 - val_rmse: 0.0114\n",
            "Epoch 275/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0035 - mse: 7.7578e-05 - rmse: 0.0088 - val_loss: 0.0037 - val_mse: 8.3241e-05 - val_rmse: 0.0091\n",
            "Epoch 276/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0036 - mse: 7.9598e-05 - rmse: 0.0089 - val_loss: 0.0039 - val_mse: 8.8949e-05 - val_rmse: 0.0094\n",
            "Epoch 277/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0035 - mse: 7.9229e-05 - rmse: 0.0089 - val_loss: 0.0041 - val_mse: 9.6851e-05 - val_rmse: 0.0098\n",
            "Epoch 278/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0035 - mse: 7.8778e-05 - rmse: 0.0089 - val_loss: 0.0037 - val_mse: 8.4487e-05 - val_rmse: 0.0092\n",
            "Epoch 279/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0035 - mse: 7.8180e-05 - rmse: 0.0088 - val_loss: 0.0041 - val_mse: 9.6789e-05 - val_rmse: 0.0098\n",
            "Epoch 280/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0035 - mse: 7.9080e-05 - rmse: 0.0089 - val_loss: 0.0046 - val_mse: 1.1518e-04 - val_rmse: 0.0107\n",
            "Epoch 281/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0034 - mse: 7.7559e-05 - rmse: 0.0088 - val_loss: 0.0042 - val_mse: 1.0181e-04 - val_rmse: 0.0101\n",
            "Epoch 282/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0034 - mse: 7.8337e-05 - rmse: 0.0089 - val_loss: 0.0039 - val_mse: 8.9788e-05 - val_rmse: 0.0095\n",
            "Epoch 283/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0035 - mse: 8.0366e-05 - rmse: 0.0090 - val_loss: 0.0038 - val_mse: 8.9387e-05 - val_rmse: 0.0095\n",
            "Epoch 284/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0034 - mse: 7.7578e-05 - rmse: 0.0088 - val_loss: 0.0040 - val_mse: 9.6046e-05 - val_rmse: 0.0098\n",
            "Epoch 285/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0034 - mse: 7.7157e-05 - rmse: 0.0088 - val_loss: 0.0040 - val_mse: 9.7542e-05 - val_rmse: 0.0099\n",
            "Epoch 286/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0034 - mse: 7.7988e-05 - rmse: 0.0088 - val_loss: 0.0036 - val_mse: 8.4579e-05 - val_rmse: 0.0092\n",
            "Epoch 287/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0034 - mse: 7.7480e-05 - rmse: 0.0088 - val_loss: 0.0035 - val_mse: 8.3242e-05 - val_rmse: 0.0091\n",
            "Epoch 288/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0034 - mse: 7.8092e-05 - rmse: 0.0088 - val_loss: 0.0034 - val_mse: 8.0275e-05 - val_rmse: 0.0090\n",
            "Epoch 289/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0033 - mse: 7.7570e-05 - rmse: 0.0088 - val_loss: 0.0037 - val_mse: 8.9539e-05 - val_rmse: 0.0095\n",
            "Epoch 290/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0033 - mse: 7.7406e-05 - rmse: 0.0088 - val_loss: 0.0042 - val_mse: 1.0643e-04 - val_rmse: 0.0103\n",
            "Epoch 291/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0033 - mse: 7.7320e-05 - rmse: 0.0088 - val_loss: 0.0037 - val_mse: 9.0711e-05 - val_rmse: 0.0095\n",
            "Epoch 292/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0032 - mse: 7.6028e-05 - rmse: 0.0087 - val_loss: 0.0035 - val_mse: 8.4741e-05 - val_rmse: 0.0092\n",
            "Epoch 293/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0032 - mse: 7.7299e-05 - rmse: 0.0088 - val_loss: 0.0037 - val_mse: 9.3346e-05 - val_rmse: 0.0097\n",
            "Epoch 294/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0032 - mse: 7.6655e-05 - rmse: 0.0088 - val_loss: 0.0045 - val_mse: 1.1763e-04 - val_rmse: 0.0108\n",
            "Epoch 295/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0032 - mse: 7.7815e-05 - rmse: 0.0088 - val_loss: 0.0035 - val_mse: 8.7538e-05 - val_rmse: 0.0094\n",
            "Epoch 296/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0033 - mse: 7.8794e-05 - rmse: 0.0089 - val_loss: 0.0038 - val_mse: 9.7258e-05 - val_rmse: 0.0099\n",
            "Epoch 297/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0032 - mse: 7.6961e-05 - rmse: 0.0088 - val_loss: 0.0033 - val_mse: 8.1984e-05 - val_rmse: 0.0091\n",
            "Epoch 298/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0032 - mse: 7.6252e-05 - rmse: 0.0087 - val_loss: 0.0035 - val_mse: 8.6294e-05 - val_rmse: 0.0093\n",
            "Epoch 299/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0031 - mse: 7.6344e-05 - rmse: 0.0087 - val_loss: 0.0033 - val_mse: 8.1955e-05 - val_rmse: 0.0091\n",
            "Epoch 300/300\n",
            "563/563 [==============================] - 25s 44ms/step - loss: 0.0031 - mse: 7.6282e-05 - rmse: 0.0087 - val_loss: 0.0042 - val_mse: 1.0958e-04 - val_rmse: 0.0105\n",
            "Best validation MSE is 8.0275465734303e-05 on epoch #288\n"
          ]
        }
      ],
      "source": [
        "model = make_model(X_TRAIN.shape[1:])\n",
        "\n",
        "model.compile(optimizer=keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n",
        "              loss=keras.losses.MeanSquaredError(reduction=keras.losses.Reduction.SUM),\n",
        "              metrics=[keras.metrics.MeanSquaredError(name='mse'),\n",
        "                       keras.metrics.RootMeanSquaredError(name='rmse')])\n",
        "\n",
        "history = model.fit(X_TRAIN, Y_TRAIN, validation_data=(X_VAL, Y_VAL),\n",
        "                    epochs=EPOCHS,\n",
        "                    callbacks=[TrackBestPerformance()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "6qJr-E3YIfP7",
        "outputId": "30ca4bc4-6736-4bc5-efe7-648cbd863d86"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1080x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "_, axes = plot.subplots(figsize=(15, 5))\n",
        "_ = axes.plot(range(1, EPOCHS + 1), history.history['mse'], label='Train data')\n",
        "_ = axes.plot(range(1, EPOCHS + 1), history.history['val_mse'], label='Validation data')\n",
        "_ = axes.set(xlabel='Epoch', ylabel='MSE', title='MSE vs Epoch step')\n",
        "_ = plot.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LRJq9RO1huqO",
        "outputId": "36e6c294-660c-4f26-ac95-23ad91a38d1c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best validation MSE: 8.0275465734303e-05\n",
            "Corresponding train MSE: 7.809164526406676e-05\n"
          ]
        }
      ],
      "source": [
        "print('Best validation MSE: {}'.format(min(history.history['val_mse'])))\n",
        "print('Corresponding train MSE: {}'.format(history.history['mse'][np.argmin(history.history['val_mse'])]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "7VUVVKD1_6sU"
      },
      "outputs": [],
      "source": [
        "X_BATCHES_TRAIN = np.array_split(X_TRAIN, 50, axis=0)\n",
        "Y_PRED_TRAIN = np.concatenate([model(x_batch).numpy() for x_batch in X_BATCHES_TRAIN], axis=0)[:, 0]\n",
        "\n",
        "X_BATCHES_VAL = np.array_split(X_VAL, 50, axis=0)\n",
        "Y_PRED_VAL = np.concatenate([model(x_batch).numpy() for x_batch in X_BATCHES_VAL], axis=0)[:, 0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fu08Sm77PFTN",
        "outputId": "9809deff-1395-45a9-f89f-eafd584e4073"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/weights/assets\n"
          ]
        }
      ],
      "source": [
        "# Save model weights\n",
        "model.save(MODELPATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gdBNjoYiPHp6",
        "outputId": "c438bf3e-f174-4210-86cf-c21612e92a7c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  adding: content/weights/ (stored 0%)\n",
            "  adding: content/weights/variables/ (stored 0%)\n",
            "  adding: content/weights/variables/variables.data-00000-of-00001 (deflated 6%)\n",
            "  adding: content/weights/variables/variables.index (deflated 75%)\n",
            "  adding: content/weights/assets/ (stored 0%)\n",
            "  adding: content/weights/keras_metadata.pb (deflated 94%)\n",
            "  adding: content/weights/saved_model.pb (deflated 89%)\n"
          ]
        }
      ],
      "source": [
        "# Compress model weights\n",
        "!zip -r './test_3_weights.zip' './weights'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "Q0HQ0hQNPMEg"
      },
      "outputs": [],
      "source": [
        "# Load model weights\n",
        "model = keras.models.load_model(MODELPATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cttp4PD7POpt",
        "outputId": "4edf105a-2d05-4801-9b8e-fb877f57e6cc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "63/63 [==============================] - 1s 9ms/step - loss: 0.0034 - mse: 8.0275e-05 - rmse: 0.0090\n"
          ]
        }
      ],
      "source": [
        "_ = model.evaluate(X_VAL, Y_VAL)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nK_3cQvaPRG7"
      },
      "outputs": [],
      "source": [
        "# Run this cell to evaluate on test data\n",
        "X_TEST, Y_TEST = None, None # load test data here. Shape: (None, 150, 150, 1)\n",
        "\n",
        "# Standardize test data\n",
        "X_TEST = ((X_TEST - np.mean(X_TEST, axis=(1, 2), keepdims=True))\n",
        "          / np.std(X_TEST, axis=(1, 2), keepdims=True))\n",
        "\n",
        "model.evaluate(X_TEST, Y_TEST)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rTc8WaCmkpEr"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "gsoc_deeplense_test_3.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
